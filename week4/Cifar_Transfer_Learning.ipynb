{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "CNN_Final.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSaN85DKFDqY"
      },
      "source": [
        "# Transfer Learning CIFAR-10(CNN's)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x1NJq9qFDqc"
      },
      "source": [
        "Libraries Included"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KaqXPqImFDqh"
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "import tensorflow as tf\n",
        "from keras.utils import np_utils\n",
        "from keras.models import load_model\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "import cv2"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vH0m8GxAFDq3"
      },
      "source": [
        "#### Model Creation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LQS-OZuFDq6"
      },
      "source": [
        "load Resnet50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-89zJL93FDq8",
        "outputId": "7a019200-c752-4b16-833c-3aaad3370a17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "source": [
        "conv_base = ResNet50(weights='imagenet', include_top=False, input_shape=(200, 200, 3))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "94773248/94765736 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "io5Gp7AgFDrN",
        "outputId": "80370d17-66c6-4a76-e708-fca1d0635dfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "conv_base.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"resnet50\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 200, 200, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 206, 206, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 100, 100, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 100, 100, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 100, 100, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 102, 102, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 50, 50, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 50, 50, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 50, 50, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 50, 50, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 50, 50, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 50, 50, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 50, 50, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 50, 50, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 50, 50, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 50, 50, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 50, 50, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 50, 50, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 50, 50, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 50, 50, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 50, 50, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 50, 50, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 50, 50, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 50, 50, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 50, 50, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 50, 50, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 50, 50, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 50, 50, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 50, 50, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 50, 50, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 50, 50, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 50, 50, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 50, 50, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 50, 50, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 25, 25, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 25, 25, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 25, 25, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 25, 25, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 25, 25, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 25, 25, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 25, 25, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 25, 25, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 25, 25, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 25, 25, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 25, 25, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 25, 25, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 25, 25, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 25, 25, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 25, 25, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 25, 25, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 25, 25, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 25, 25, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 25, 25, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 25, 25, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 25, 25, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 25, 25, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 25, 25, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 25, 25, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 25, 25, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 25, 25, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 25, 25, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 25, 25, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 25, 25, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 25, 25, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 25, 25, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 25, 25, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 25, 25, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 25, 25, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 25, 25, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 13, 13, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 13, 13, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 13, 13, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 13, 13, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 13, 13, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 13, 13, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 13, 13, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 13, 13, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 13, 13, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 13, 13, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 13, 13, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 13, 13, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 13, 13, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 13, 13, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 13, 13, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 13, 13, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 13, 13, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 13, 13, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 13, 13, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 13, 13, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 13, 13, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 13, 13, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 13, 13, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 13, 13, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 13, 13, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 13, 13, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 13, 13, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 13, 13, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 13, 13, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 13, 13, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 13, 13, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 13, 13, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 13, 13, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 13, 13, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 13, 13, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 13, 13, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 13, 13, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 13, 13, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 13, 13, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 13, 13, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 13, 13, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 13, 13, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 13, 13, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 13, 13, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 13, 13, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 13, 13, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
            "==================================================================================================\n",
            "Total params: 23,587,712\n",
            "Trainable params: 23,534,592\n",
            "Non-trainable params: 53,120\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqTz4cm-FDrZ"
      },
      "source": [
        "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbfgXLDYFDrc"
      },
      "source": [
        "*Changed the dataset*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8LWY_2dFDrd",
        "outputId": "f4891dc5-0943-4d4f-d290-a2375fcc08d5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from keras.datasets import cifar10\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train / 255.0\n",
        "x_test = x_test / 255.0\n",
        "\n",
        "y_train = np_utils.to_categorical(y_train, 10)\n",
        "y_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 4s 0us/step\n",
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sxVUJtyFDro"
      },
      "source": [
        "To train our model on the new dataset above, the architecture for everything besides the ResNet 50 portion has changed. To begin with, the input image of Cifar10 is 32x32 so it needs to be upscaled 3 times before we can pass it through the ResNet layers. After the images go through ResNet, we flatten our processed input and pass it though 2 dense layers. Each layer has batch normalization beforehand and dropout coming out before the last layer, with softmax and 10 neurons. Since the method below is computationally expensive, let's only train it for 5 epochs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joGrNGr6FDrr"
      },
      "source": [
        "*Added layers and changed architecture*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RgJ9IoOFDru"
      },
      "source": [
        "*Retrained the model*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcU1oWxgFDrx",
        "outputId": "b2251237-deeb-4e7c-8662-aa86450a72bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 314
        }
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.UpSampling2D((2,2)))\n",
        "model.add(layers.UpSampling2D((2,2)))\n",
        "model.add(layers.UpSampling2D((2,2)))\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(128, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer=optimizers.RMSprop(lr=2e-5), loss='binary_crossentropy', metrics=['acc'])\n",
        "\n",
        "history = model.fit(x_train, y_train, epochs=5, batch_size=20, validation_data=(x_test, y_test))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 200, 200, 3) for input Tensor(\"input_1:0\", shape=(None, 200, 200, 3), dtype=float32), but it was called on an input with incompatible shape (20, 256, 256, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 200, 200, 3) for input Tensor(\"input_1:0\", shape=(None, 200, 200, 3), dtype=float32), but it was called on an input with incompatible shape (20, 256, 256, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 200, 200, 3) for input Tensor(\"input_1:0\", shape=(None, 200, 200, 3), dtype=float32), but it was called on an input with incompatible shape (20, 256, 256, 3).\n",
            "2500/2500 [==============================] - ETA: 0s - loss: 0.2471 - acc: 0.4549WARNING:tensorflow:Model was constructed with shape (None, 200, 200, 3) for input Tensor(\"input_1:0\", shape=(None, 200, 200, 3), dtype=float32), but it was called on an input with incompatible shape (20, 256, 256, 3).\n",
            "WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0062s vs `on_test_batch_end` time: 0.0716s). Check your callbacks.\n",
            "2500/2500 [==============================] - 725s 290ms/step - loss: 0.2471 - acc: 0.4549 - val_loss: 0.1112 - val_acc: 0.8161\n",
            "Epoch 2/5\n",
            "2500/2500 [==============================] - 726s 290ms/step - loss: 0.1580 - acc: 0.7050 - val_loss: 0.0729 - val_acc: 0.8890\n",
            "Epoch 3/5\n",
            "2500/2500 [==============================] - 726s 291ms/step - loss: 0.1196 - acc: 0.8010 - val_loss: 0.0545 - val_acc: 0.9180\n",
            "Epoch 4/5\n",
            "2500/2500 [==============================] - 725s 290ms/step - loss: 0.0942 - acc: 0.8579 - val_loss: 0.0447 - val_acc: 0.9317\n",
            "Epoch 5/5\n",
            "2500/2500 [==============================] - 725s 290ms/step - loss: 0.0759 - acc: 0.8911 - val_loss: 0.0372 - val_acc: 0.9395\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv5HpeoxFDsO",
        "outputId": "46da803a-8bad-481d-f122-602c537d964c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        }
      },
      "source": [
        "model.evaluate(x_test, y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Model was constructed with shape (None, 200, 200, 3) for input Tensor(\"input_1:0\", shape=(None, 200, 200, 3), dtype=float32), but it was called on an input with incompatible shape (None, 256, 256, 3).\n",
            "WARNING:tensorflow:Model was constructed with shape (None, 200, 200, 3) for input Tensor(\"input_1:0\", shape=(None, 200, 200, 3), dtype=float32), but it was called on an input with incompatible shape (None, 256, 256, 3).\n",
            "313/313 [==============================] - 42s 136ms/step - loss: 0.0372 - acc: 0.9395\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.037207625806331635, 0.9394999742507935]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zSclf0BhFDsY",
        "outputId": "8fb37209-ece1-416b-e2b9-001ee136cfea"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "up_sampling2d (UpSampling2D) multiple                  0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_1 (UpSampling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d_2 (UpSampling2 multiple                  0         \n",
            "_________________________________________________________________\n",
            "resnet50 (Model)             (None, 7, 7, 2048)        23587712  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_v2 (Batc multiple                  524288    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  16777344  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            multiple                  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_v2_1 (Ba multiple                  512       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              multiple                  8256      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          multiple                  0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_v2_2 (Ba multiple                  256       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              multiple                  650       \n",
            "=================================================================\n",
            "Total params: 40,899,018\n",
            "Trainable params: 40,583,370\n",
            "Non-trainable params: 315,648\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mVJEZ8yaFDsk"
      },
      "source": [
        "Training/validation loss and accuracy visualizations are below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvKBKXlxFDsn",
        "outputId": "4a616047-36b0-40ca-9750-f3484a4894da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "plt.figure(figsize=(14, 4))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training Loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(epochs, acc, 'bo', label='Training Accuracy', c='orange')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy', c='orange')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7ff1cd145f28>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}